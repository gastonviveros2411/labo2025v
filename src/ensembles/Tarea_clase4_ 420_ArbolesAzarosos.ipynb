{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gastonviveros2411/labo2025v/blob/main/src/ensembles/Tarea_clase4_%20420_ArbolesAzarosos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ensembles de Arboles de Decision"
      ],
      "metadata": {
        "id": "kgJ0E--L0n9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un arbol de decisión es un modelo débil, el aumento del poder predictivo proviene al ensamblar varios arboles de decisión.\n",
        "<br> Si promedio n arboles identicos, el resultados es exactamente el mismo que utilizar un solo arbol, necesito PERTURBAR cada arbol para disponer de variablidad"
      ],
      "metadata": {
        "id": "PgLdmWznXWGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "la variabilidad provendrá de estas fuentes:\n",
        "\n",
        "\n",
        "*   Perturbar el dataset\n",
        "*   Perturbar el algoritmo del arbol\n",
        "*   Perturbar el dataset y el algoritmo del arbol al mismo tiempo"
      ],
      "metadata": {
        "id": "FTnxMEOqYRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se verán estos tres algoritmos\n",
        "\n",
        "\n",
        "*   Arboles Azarosos\n",
        "*   Random Forest\n",
        "*   Gradient Boosting of Decision Trees"
      ],
      "metadata": {
        "id": "DHp1h9m-X7Rc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0ySYPfa7Zr"
      },
      "source": [
        "#### 4.01 Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs"
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9x9DnsNlZv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.02 Arboles Azarosos"
      ],
      "metadata": {
        "id": "qq0KVOtq1K5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arboles Azarosos es el nombre de un algoritmo trivial (por favor NO confundir con Random Forest)\n",
        "Qué tipo de perturbaciones se realizan en Arboles Azarosos\n",
        "* Se perturba el dataset\n",
        "* No se perturba el algoritmo, es siempre rpart original"
      ],
      "metadata": {
        "id": "HsNJjhlRo9jM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada  arbolito de  Arboles Azarosos se entrena sobre un dataset perturbado,  que tiene exactamente la misma cantidad de registros pero solo un subconjunto de los atributos (campos)  del dataset, tomados al azar, de los originales.\n",
        "<br> En esta primera corrida, se construira cada arbol en un dataset utilizando el 50% de los campos"
      ],
      "metadata": {
        "id": "rq2HC28CpXBR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "BPKNVHx5mmcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo las librerias necesarias\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "\n",
        "# Instalar rBayesianOptimization si no está instalado\n",
        "if (!require(\"rBayesianOptimization\")) {\n",
        "  install.packages(\"rBayesianOptimization\", repos=\"http://cran.us.r-project.org\")\n",
        "  library(\"rBayesianOptimization\")\n",
        "}"
      ],
      "metadata": {
        "id": "lu7YQvh2mmiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aquí debe cargar SU semilla primigenia\n",
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 102191  # CAMBIAR POR TU SEMILLA\n",
        "\n",
        "# feature_fraction se mantiene fijo en 0.5\n",
        "PARAM$feature_fraction <- 0.5\n",
        "\n",
        "# Cantidad de árboles fija en 32\n",
        "PARAM$num_trees <- 32\n",
        "\n",
        "# cp FIJO en -1 (no se optimiza)\n",
        "PARAM$cp_fijo <- -1\n",
        "\n",
        "# Parámetros de la Optimización Bayesiana\n",
        "PARAM$bo_iteraciones <- 50  # número de iteraciones de optimización\n",
        "PARAM$bo_init_points <- 10  # puntos de inicialización aleatoria\n",
        "\n",
        "cat(\"Configuración de Optimización Bayesiana:\\n\")\n",
        "cat(\"- Iteraciones:\", PARAM$bo_iteraciones, \"\\n\")\n",
        "cat(\"- Puntos iniciales:\", PARAM$bo_init_points, \"\\n\")\n",
        "cat(\"- Total de evaluaciones:\", PARAM$bo_iteraciones + PARAM$bo_init_points, \"\\n\")\n",
        "cat(\"- Árboles por ensemble:\", PARAM$num_trees, \"\\n\")\n",
        "cat(\"- cp FIJO:\", PARAM$cp_fijo, \"\\n\")\n",
        "cat(\"\\nTiempo estimado: 1-2 horas\\n\")"
      ],
      "metadata": {
        "id": "6Tqy_6Ufmmoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- \"exp4020_bayesiano\"\n",
        "dir.create(experimento, showWarnings=FALSE)\n",
        "setwd(paste0(\"/content/buckets/b1/exp/\", experimento))"
      ],
      "metadata": {
        "id": "fDNhBgfim_8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "9eOB0wNCnAB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos 202107 para entrenamiento\n",
        "dtrain <- dataset[foto_mes == 202107]\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia)\n",
        "\n",
        "# Separación 70% train, 30% validation\n",
        "indices_train <- sample(1:nrow(dtrain), size=0.7*nrow(dtrain))\n",
        "dtrain_real <- dtrain[indices_train]\n",
        "dvalidation <- dtrain[-indices_train]\n",
        "\n",
        "# Dataset futuro (para predicción final)\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "dfuture[, clase_ternaria := NA]\n",
        "\n",
        "cat(\"Registros training:\", nrow(dtrain_real), \"\\n\")\n",
        "cat(\"Registros validation:\", nrow(dvalidation), \"\\n\")\n",
        "cat(\"Registros future:\", nrow(dfuture), \"\\n\")"
      ],
      "metadata": {
        "id": "KEp46JiNnAFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Campos para predicción\n",
        "campos_buenos <- copy(setdiff(colnames(dtrain_real), c(\"clase_ternaria\")))\n",
        "cat(\"Cantidad de campos disponibles:\", length(campos_buenos), \"\\n\")"
      ],
      "metadata": {
        "id": "5u8sAWsCnAI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para calcular ganancia\n",
        "calcular_ganancia <- function(probs, real, corte) {\n",
        "  predicho <- as.numeric(probs > corte)\n",
        "\n",
        "  # Ganancia: BAJA+2 vale +117000, otros -3000\n",
        "  ganancia <- sum(\n",
        "    (predicho == 1 & real == \"BAJA+2\") * 117000 +\n",
        "    (predicho == 1 & real != \"BAJA+2\") * (-3000)\n",
        "  )\n",
        "\n",
        "  return(ganancia)\n",
        "}\n",
        "\n",
        "# Función para entrenar ensemble y encontrar mejor ganancia\n",
        "entrenar_ensemble <- function(minsplit, minbucket, maxdepth) {\n",
        "\n",
        "  # cp es FIJO desde PARAM\n",
        "  cp <- PARAM$cp_fijo\n",
        "\n",
        "  # Convertir a enteros los parámetros discretos\n",
        "  minsplit <- as.integer(round(minsplit))\n",
        "  minbucket <- as.integer(round(minbucket))\n",
        "  maxdepth <- as.integer(round(maxdepth))\n",
        "\n",
        "  # Validación: minbucket debe ser <= minsplit/2\n",
        "  if (minbucket > minsplit / 2) {\n",
        "    minbucket <- as.integer(minsplit / 2)\n",
        "  }\n",
        "\n",
        "  # Validaciones adicionales\n",
        "  if (minsplit < 2) minsplit <- 2\n",
        "  if (minbucket < 1) minbucket <- 1\n",
        "  if (maxdepth < 1) maxdepth <- 1\n",
        "  if (maxdepth > 30) maxdepth <- 30\n",
        "\n",
        "  # Vector para acumular probabilidades\n",
        "  prob_acum_val <- rep(0, nrow(dvalidation))\n",
        "\n",
        "  # Entrenar los árboles\n",
        "  for (arbol in 1:PARAM$num_trees) {\n",
        "    # Selección aleatoria de campos\n",
        "    qty_campos <- as.integer(length(campos_buenos) * PARAM$feature_fraction)\n",
        "    campos_random <- sample(campos_buenos, qty_campos)\n",
        "    campos_str <- paste(campos_random, collapse=\" + \")\n",
        "    formulita <- paste0(\"clase_ternaria ~ \", campos_str)\n",
        "\n",
        "    # Entrenar árbol con manejo de errores\n",
        "    tryCatch({\n",
        "      modelo <- rpart(\n",
        "        formulita,\n",
        "        data=dtrain_real,\n",
        "        xval=0,\n",
        "        control=list(\n",
        "          cp=cp,\n",
        "          minsplit=minsplit,\n",
        "          minbucket=minbucket,\n",
        "          maxdepth=maxdepth\n",
        "        )\n",
        "      )\n",
        "\n",
        "      # Predicción en validación\n",
        "      pred <- predict(modelo, dvalidation, type=\"prob\")\n",
        "      prob_acum_val <- prob_acum_val + pred[, \"BAJA+2\"]\n",
        "    }, error = function(e) {\n",
        "      # Si hay error, usar predicción neutra\n",
        "      cat(\"Error en árbol\", arbol, \":\", e$message, \"\\n\")\n",
        "    })\n",
        "  }\n",
        "\n",
        "  # Probabilidad promedio\n",
        "  prob_promedio <- prob_acum_val / PARAM$num_trees\n",
        "\n",
        "  # Buscar mejor punto de corte (más rápido, menos granular)\n",
        "  cortes <- seq(0.025, 0.5, by=0.025)  # rango más acotado\n",
        "  ganancias <- sapply(cortes, function(c) {\n",
        "    calcular_ganancia(prob_promedio, dvalidation$clase_ternaria, c)\n",
        "  })\n",
        "\n",
        "  mejor_ganancia <- max(ganancias)\n",
        "\n",
        "  return(mejor_ganancia)\n",
        "}"
      ],
      "metadata": {
        "id": "EAU30RjonALb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contador global para tracking\n",
        "iteracion_global <- 0\n",
        "mejor_ganancia_global <- -Inf\n",
        "mejores_params_global <- list()\n",
        "\n",
        "# Historial de evaluaciones\n",
        "historial <- data.table(\n",
        "  iteracion=integer(),\n",
        "  cp=numeric(),\n",
        "  minsplit=numeric(),\n",
        "  minbucket=numeric(),\n",
        "  maxdepth=numeric(),\n",
        "  ganancia=numeric(),\n",
        "  tiempo_seg=numeric()\n",
        ")\n",
        "\n",
        "# Función objetivo que optimizará la BO\n",
        "# IMPORTANTE: La BO MAXIMIZA esta función\n",
        "funcion_objetivo <- function(minsplit, minbucket, maxdepth) {\n",
        "\n",
        "  iteracion_global <<- iteracion_global + 1\n",
        "  tiempo_inicio <- Sys.time()\n",
        "\n",
        "  cat(sprintf(\"\\n[Iter %d] Evaluando: cp=%.2f (FIJO), minsplit=%d, minbucket=%d, maxdepth=%d\\n\",\n",
        "              iteracion_global, PARAM$cp_fijo, round(minsplit), round(minbucket), round(maxdepth)))\n",
        "\n",
        "  # Entrenar y evaluar\n",
        "  ganancia <- entrenar_ensemble(minsplit, minbucket, maxdepth)\n",
        "\n",
        "  tiempo_fin <- Sys.time()\n",
        "  tiempo_transcurrido <- as.numeric(difftime(tiempo_fin, tiempo_inicio, units=\"secs\"))\n",
        "\n",
        "  cat(sprintf(\"Ganancia: $%.0f | Tiempo: %.1fs\",\n",
        "              ganancia, tiempo_transcurrido))\n",
        "\n",
        "  # Actualizar mejor resultado\n",
        "  if (ganancia > mejor_ganancia_global) {\n",
        "    mejor_ganancia_global <<- ganancia\n",
        "    mejores_params_global <<- list(\n",
        "      cp=PARAM$cp_fijo,\n",
        "      minsplit=round(minsplit),\n",
        "      minbucket=round(minbucket),\n",
        "      maxdepth=round(maxdepth)\n",
        "    )\n",
        "    cat(\" ★ NUEVO MEJOR! ★\")\n",
        "  }\n",
        "  cat(\"\\n\")\n",
        "\n",
        "  # Guardar en historial\n",
        "  historial <<- rbind(historial, data.table(\n",
        "    iteracion=iteracion_global,\n",
        "    cp=PARAM$cp_fijo,\n",
        "    minsplit=round(minsplit),\n",
        "    minbucket=round(minbucket),\n",
        "    maxdepth=round(maxdepth),\n",
        "    ganancia=ganancia,\n",
        "    tiempo_seg=tiempo_transcurrido\n",
        "  ))\n",
        "\n",
        "  # Guardar archivo intermedio cada 5 iteraciones\n",
        "  if (iteracion_global %% 5 == 0) {\n",
        "    fwrite(historial, \"historial_bayesiano_parcial.csv\")\n",
        "  }\n",
        "\n",
        "  # Retornar ganancia normalizada (para ayudar a la BO)\n",
        "  # La BO trabaja mejor con valores en rango razonable\n",
        "  return(list(Score = ganancia / 1000000))  # normalizado a millones\n",
        "}"
      ],
      "metadata": {
        "id": "bCrJvTOHnAOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los límites de búsqueda para cada hiperparámetro\n",
        "# La BO puede explorar valores continuos en estos rangos\n",
        "\n",
        "bounds <- list(\n",
        "  # cp es FIJO en -1, NO se optimiza\n",
        "  minsplit = c(10, 400),      # mínimo para intentar split\n",
        "  minbucket = c(5, 200),      # mínimo en hoja\n",
        "  maxdepth = c(3, 15)         # profundidad máxima\n",
        ")\n",
        "\n",
        "cat(\"Rangos de búsqueda:\\n\")\n",
        "cat(\"- cp:\", PARAM$cp_fijo, \"(FIJO)\\n\")\n",
        "cat(\"- minsplit:\", bounds$minsplit, \"\\n\")\n",
        "cat(\"- minbucket:\", bounds$minbucket, \"\\n\")\n",
        "cat(\"- maxdepth:\", bounds$maxdepth, \"\\n\")"
      ],
      "metadata": {
        "id": "ykFl3gJUnAQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat(\"\\n=== INICIO DE OPTIMIZACIÓN BAYESIANA ===\\n\")\n",
        "cat(\"Ensemble de\", PARAM$num_trees, \"árboles\\n\")\n",
        "cat(\"Feature fraction:\", PARAM$feature_fraction, \"\\n\")\n",
        "cat(\"Evaluaciones totales:\", PARAM$bo_iteraciones + PARAM$bo_init_points, \"\\n\\n\")\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia)\n",
        "tiempo_inicio_total <- Sys.time()\n",
        "\n",
        "# Ejecutar optimización bayesiana\n",
        "resultado_bo <- BayesianOptimization(\n",
        "  FUN = funcion_objetivo,\n",
        "  bounds = bounds,\n",
        "  init_points = PARAM$bo_init_points,  # exploración inicial aleatoria\n",
        "  n_iter = PARAM$bo_iteraciones,        # iteraciones de optimización\n",
        "  acq = \"ucb\",                          # función de adquisición: Upper Confidence Bound\n",
        "  kappa = 2.576,                        # exploración vs explotación\n",
        "  eps = 0.0,\n",
        "  verbose = TRUE\n",
        ")\n",
        "\n",
        "tiempo_fin_total <- Sys.time()\n",
        "tiempo_total <- as.numeric(difftime(tiempo_fin_total, tiempo_inicio_total, units=\"mins\"))\n",
        "\n",
        "cat(\"\\n=== OPTIMIZACIÓN COMPLETADA ===\\n\")\n",
        "cat(sprintf(\"Tiempo total: %.1f minutos\\n\", tiempo_total))"
      ],
      "metadata": {
        "id": "l_Ii__3snAS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar historial completo\n",
        "fwrite(historial, \"historial_bayesiano_completo.csv\")\n",
        "\n",
        "# Ordenar por ganancia\n",
        "historial_ordenado <- historial[order(-ganancia)]\n",
        "\n",
        "cat(\"\\n=== TOP 10 MEJORES CONFIGURACIONES ===\\n\")\n",
        "print(historial_ordenado[1:min(10, nrow(historial_ordenado))])\n",
        "\n",
        "# Mejor configuración encontrada\n",
        "mejor_config <- historial_ordenado[1]\n",
        "\n",
        "cat(\"\\n=== MEJOR CONFIGURACIÓN ENCONTRADA ===\\n\")\n",
        "cat(sprintf(\"cp: %.4f\\n\", mejor_config$cp))\n",
        "cat(sprintf(\"minsplit: %d\\n\", mejor_config$minsplit))\n",
        "cat(sprintf(\"minbucket: %d\\n\", mejor_config$minbucket))\n",
        "cat(sprintf(\"maxdepth: %d\\n\", mejor_config$maxdepth))\n",
        "cat(sprintf(\"Ganancia en validación: $%.0f\\n\", mejor_config$ganancia))\n",
        "\n",
        "# Estadísticas de la búsqueda\n",
        "cat(\"\\n=== ESTADÍSTICAS DE LA BÚSQUEDA ===\\n\")\n",
        "cat(sprintf(\"Ganancia mínima explorada: $%.0f\\n\", min(historial$ganancia)))\n",
        "cat(sprintf(\"Ganancia máxima explorada: $%.0f\\n\", max(historial$ganancia)))\n",
        "cat(sprintf(\"Ganancia promedio: $%.0f\\n\", mean(historial$ganancia)))\n",
        "cat(sprintf(\"Desviación estándar: $%.0f\\n\", sd(historial$ganancia)))\n",
        "cat(sprintf(\"Mejora sobre promedio: %.1f%%\\n\",\n",
        "            100 * (mejor_config$ganancia - mean(historial$ganancia)) / mean(historial$ganancia)))"
      ],
      "metadata": {
        "id": "lc9zOw6QnAVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de convergencia\n",
        "historial[, mejor_hasta_ahora := cummax(ganancia)]\n",
        "\n",
        "cat(\"\\n=== EVOLUCIÓN DE LA BÚSQUEDA ===\\n\")\n",
        "cat(\"Iteración | Ganancia Actual | Mejor Hasta Ahora\\n\")\n",
        "cat(\"----------|-----------------|------------------\\n\")\n",
        "\n",
        "# Mostrar cada 5 iteraciones\n",
        "indices_muestra <- seq(1, nrow(historial), by=5)\n",
        "for (i in indices_muestra) {\n",
        "  cat(sprintf(\"%9d | $%14.0f | $%14.0f\\n\",\n",
        "              historial$iteracion[i],\n",
        "              historial$ganancia[i],\n",
        "              historial$mejor_hasta_ahora[i]))\n",
        "}\n",
        "\n",
        "# Última iteración si no está en la muestra\n",
        "if (!(nrow(historial) %in% indices_muestra)) {\n",
        "  i <- nrow(historial)\n",
        "  cat(sprintf(\"%9d | $%14.0f | $%14.0f\\n\",\n",
        "              historial$iteracion[i],\n",
        "              historial$ganancia[i],\n",
        "              historial$mejor_hasta_ahora[i]))\n",
        "}"
      ],
      "metadata": {
        "id": "o6fHJEIanAXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat(\"\\n=== ANÁLISIS DE SENSIBILIDAD ===\\n\\n\")\n",
        "\n",
        "# Dividir en cuartiles cada hiperparámetro y ver ganancia promedio\n",
        "analisis_param <- function(nombre_param) {\n",
        "  valores <- historial[[nombre_param]]\n",
        "  cuartiles <- quantile(valores, probs=c(0, 0.25, 0.5, 0.75, 1))\n",
        "\n",
        "  historial[, cuartil := cut(get(nombre_param), breaks=cuartiles,\n",
        "                              include.lowest=TRUE, labels=1:4)]\n",
        "\n",
        "  resumen <- historial[, .(ganancia_media = mean(ganancia),\n",
        "                           ganancia_max = max(ganancia),\n",
        "                           n = .N), by=cuartil]\n",
        "\n",
        "  cat(\"\\n\", toupper(nombre_param), \":\\n\")\n",
        "  cat(sprintf(\"Rango explorado: [%.2f, %.2f]\\n\", min(valores), max(valores)))\n",
        "  print(resumen)\n",
        "\n",
        "  historial[, cuartil := NULL]\n",
        "}\n",
        "\n",
        "analisis_param(\"cp\")\n",
        "analisis_param(\"minsplit\")\n",
        "analisis_param(\"minbucket\")\n",
        "analisis_param(\"maxdepth\")"
      ],
      "metadata": {
        "id": "o8ON7j1LnAZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat(\"\\n=== ENTRENANDO MODELO FINAL ===\\n\")\n",
        "cat(\"Usando TODO el dataset de 202107 con mejor configuración\\n\\n\")\n",
        "\n",
        "# Preparar tabla de predicción\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob_acumulada := 0]\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia)\n",
        "\n",
        "# Entrenar ensemble final con mejores hiperparámetros\n",
        "for (arbolito in seq(PARAM$num_trees)) {\n",
        "  if (arbolito %% 5 == 0) cat(arbolito, \" \")\n",
        "\n",
        "  qty_campos <- as.integer(length(campos_buenos) * PARAM$feature_fraction)\n",
        "  campos_random <- sample(campos_buenos, qty_campos)\n",
        "  campos_str <- paste(campos_random, collapse=\" + \")\n",
        "  formulita <- paste0(\"clase_ternaria ~ \", campos_str)\n",
        "\n",
        "  modelo <- rpart(\n",
        "    formulita,\n",
        "    data=dtrain,  # TODO el dataset de 202107\n",
        "    xval=0,\n",
        "    control=list(\n",
        "      cp=mejor_config$cp,\n",
        "      minsplit=mejor_config$minsplit,\n",
        "      minbucket=mejor_config$minbucket,\n",
        "      maxdepth=mejor_config$maxdepth\n",
        "    )\n",
        "  )\n",
        "\n",
        "  prediccion <- predict(modelo, dfuture, type=\"prob\")\n",
        "  tb_prediccion[, prob_acumulada := prob_acumulada + prediccion[, \"BAJA+2\"]]\n",
        "}\n",
        "\n",
        "cat(\"\\n\\n\")\n",
        "\n",
        "# Encontrar mejor punto de corte en las probabilidades acumuladas\n",
        "# Probamos diferentes umbrales\n",
        "cortes_test <- seq(0.5, 2.0, by=0.05) * PARAM$num_trees\n",
        "envios <- sapply(cortes_test, function(c) sum(tb_prediccion$prob_acumulada > c))\n",
        "\n",
        "cat(\"Análisis de puntos de corte:\\n\")\n",
        "cat(\"Umbral (prob acum) | Cantidad de envíos\\n\")\n",
        "cat(\"-------------------|------------------\\n\")\n",
        "for (i in seq_along(cortes_test)[c(1, seq(5, length(cortes_test), by=5))]) {\n",
        "  cat(sprintf(\"%18.2f | %16d\\n\", cortes_test[i], envios[i]))\n",
        "}\n",
        "\n",
        "# Usar un corte que dé aproximadamente 8000-12000 envíos (ajustar según tu caso)\n",
        "objetivo_envios <- 10000\n",
        "idx_corte <- which.min(abs(envios - objetivo_envios))\n",
        "umbral_corte <- cortes_test[idx_corte]\n",
        "\n",
        "tb_prediccion[, Predicted := as.numeric(prob_acumulada > umbral_corte)]\n",
        "\n",
        "archivo_kaggle <- \"KA420_bayesiano_32arboles.csv\"\n",
        "fwrite(\n",
        "  tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "  file=archivo_kaggle,\n",
        "  sep=\",\"\n",
        ")\n",
        "\n",
        "cat(\"\\nArchivo de predicción generado:\", archivo_kaggle, \"\\n\")\n",
        "cat(\"Umbral de corte usado:\", umbral_corte, \"\\n\")\n",
        "cat(\"Registros predichos como BAJA+2:\", sum(tb_prediccion$Predicted), \"\\n\")"
      ],
      "metadata": {
        "id": "FSN3wXaAnAb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subida a Kaggle\n",
        "mensaje <- sprintf(\n",
        "  \"Bayesian Opt 32 arboles - cp=-1(fijo) ms=%d mb=%d md=%d\",\n",
        "  mejor_config$minsplit,\n",
        "  mejor_config$minbucket, mejor_config$maxdepth\n",
        ")\n",
        "\n",
        "comando <- \"kaggle competitions submit\"\n",
        "competencia <- \"-c labo-i-2025-ba-analista-sr\"\n",
        "arch <- paste(\"-f\", archivo_kaggle)\n",
        "mensaje_cmd <- paste0(\"-m '\", mensaje, \"'\")\n",
        "\n",
        "linea <- paste(comando, competencia, arch, mensaje_cmd)\n",
        "cat(\"\\nEjecutando:\", linea, \"\\n\\n\")\n",
        "salida <- system(linea, intern=TRUE)\n",
        "cat(salida)"
      ],
      "metadata": {
        "id": "rgtzUODrnAeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "rRFvcUxenU_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat(\"\\n\" , \"=\", \"=\", \"=\", \" RESUMEN FINAL \", \"=\", \"=\", \"=\", \"\\n\\n\")\n",
        "\n",
        "cat(\"CONFIGURACIÓN ÓPTIMA ENCONTRADA:\\n\")\n",
        "cat(\"--------------------------------\\n\")\n",
        "cat(sprintf(\"  cp:        %.4f\\n\", mejor_config$cp))\n",
        "cat(sprintf(\"  minsplit:  %d\\n\", mejor_config$minsplit))\n",
        "cat(sprintf(\"  minbucket: %d\\n\", mejor_config$minbucket))\n",
        "cat(sprintf(\"  maxdepth:  %d\\n\", mejor_config$maxdepth))\n",
        "cat(\"\\n\")\n",
        "cat(sprintf(\"Ganancia en validación: $%.0f\\n\", mejor_config$ganancia))\n",
        "cat(sprintf(\"Evaluaciones realizadas: %d\\n\", nrow(historial)))\n",
        "cat(sprintf(\"Tiempo total: %.1f minutos\\n\", tiempo_total))\n",
        "cat(sprintf(\"Tiempo promedio por evaluación: %.1f segundos\\n\",\n",
        "            mean(historial$tiempo_seg)))\n",
        "\n",
        "cat(\"\\nARCHIVOS GENERADOS:\\n\")\n",
        "cat(\"-------------------\\n\")\n",
        "cat(\"  • historial_bayesiano_completo.csv\\n\")\n",
        "cat(\"  • KA420_bayesiano_32arboles.csv\\n\")\n",
        "\n",
        "cat(\"\\nPRÓXIMOS PASOS:\\n\")\n",
        "cat(\"--------------\\n\")\n",
        "cat(\"1. Comparar estos resultados con árbol único\\n\")\n",
        "cat(\"2. Analizar diferencias en hiperparámetros\\n\")\n",
        "cat(\"3. Verificar score en Kaggle\\n\")\n",
        "cat(\"4. Documentar conclusiones\\n\")\n",
        "\n",
        "cat(\"\\n\" , \"=\", \"=\", \"=\", \"=\", \"=\", \"=\", \"=\", \"=\", \"=\", \"=\", \"=\", \"=\", \"\\n\")"
      ],
      "metadata": {
        "id": "XPV5zeB3nWOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HbldB0BhnWX0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}